{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-13T03:02:07.696780Z","iopub.status.busy":"2023-07-13T03:02:07.695851Z","iopub.status.idle":"2023-07-13T03:02:19.514467Z","shell.execute_reply":"2023-07-13T03:02:19.513198Z","shell.execute_reply.started":"2023-07-13T03:02:07.696722Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import os\n","import copy\n","import matplotlib.pyplot as plt\n","\n","import pandas as pd\n","import numpy as np\n","import librosa\n","from numpy import random\n","\n","import librosa.display\n","\n","training_groundtruth = pd.read_csv('/kaggle/input/training-groundtruth/training-groundtruth-new.csv')\n","AUDIO_FILES_DIR = '/kaggle/input/mp3files-nodoctor/rmDoc-audio/'\n","AUDIO_FILES = sorted([x for x in os.listdir(AUDIO_FILES_DIR) if x[-4:]=='.wav'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def noise(data):\n","    noise_amp = 0.03*np.random.uniform()*np.amax(data)\n","    data = data + noise_amp*np.random.normal(size=data.shape[0])\n","    return data\n","def shift(data):\n","    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n","    return np.roll(data, shift_range)\n","def pitch(data, sampling_rate, pitch_factor=0.7):\n","    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)\n","def _plot_signal_and_augmented_signal(signal, augmented_signal, sr):\n","    fig, ax = plt.subplots(nrows=2)\n","    librosa.display.waveshow(signal, sr=sr, ax=ax[0])\n","    ax[0].set(title='Original Signal')\n","    librosa.display.waveshow(augmented_signal, sr=sr, ax=ax[1])\n","    ax[1].set(title='Augmented Signal')\n","    plt.show()\n","# Code copied and edited from https://www.kaggle.com/code/davids1992/specaugment-quick-implementation\n","def spec_augment(original_melspec,\n","                 freq_masking_max_percentage = 0.05, \n","                 time_masking_max_percentage = 0.05):\n","\n","    augmented_melspec = original_melspec.copy()\n","    all_frames_num, all_freqs_num = augmented_melspec.shape\n","\n","    # Frequency masking\n","    freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n","    num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n","    f0 = int(np.random.uniform(low = 0.0, high = (all_freqs_num - num_freqs_to_mask)))\n","    \n","    augmented_melspec[:, f0:(f0 + num_freqs_to_mask)] = 0\n","\n","    # Time masking\n","    time_percentage = random.uniform(0.0, time_masking_max_percentage)\n","    num_frames_to_mask = int(time_percentage * all_frames_num)\n","    t0 = int(np.random.uniform(low = 0.0, high = (all_frames_num - num_frames_to_mask)))\n","    \n","    augmented_melspec[t0:(t0 + num_frames_to_mask), :] = 0\n","    \n","    return augmented_melspec"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# https://www.kaggle.com/code/abduallahhussien/speech-emotion-recognition-93-accuracy\n","def extract_features(data, sr, SpecAugment = False):\n","    \n","    result = np.array([])\n","    \n","    mfccs = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13)\n","    if SpecAugment:\n","        mfccs = spec_augment(mfccs)\n","     \n","    return mfccs\n","\n","def get_features(path):\n","    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n","    data, sample_rate = librosa.load(path, duration=70, offset=0.5, sr=None)\n","    avg_Size = sample_rate*70\n","    data = np.pad(data, (0,max(0,avg_Size-len(data))), 'constant')\n","    \n","    #without augmentation\n","    res1 = extract_features(data, sample_rate)\n","    result = np.array(np.expand_dims(res1, axis=0))\n","    \n","    #noised\n","    noise_data = noise(data)\n","    res2 = extract_features(noise_data, sample_rate)\n","    result = np.vstack((result, np.expand_dims(res2, axis=0))) # stacking vertically\n","    \n","    #pitched\n","    pitch_data = pitch(data, sample_rate)\n","    res5 = extract_features(pitch_data, sample_rate)\n","    result = np.vstack((result, np.expand_dims(res5, axis=0))) \n","                     \n","    #SpecAugment\n","    res8 = extract_features(data, sample_rate, True)\n","    result = np.vstack((result, np.expand_dims(res8, axis=0)))\n","                     \n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_train = []\n","data_test = []\n","x_train = []\n","x_test = []\n","y_train = []\n","y_test = []\n","length = 0\n","cou = 0\n","\n","LoadSave = True\n","LoadAddress = '/kaggle/input/mfcc13-70s/mfcc13.npy'\n","\n","if not LoadSave:\n","    for index, row in training_groundtruth.iterrows():\n","        row['index'] = index\n","        length+=1\n","        if row['type'] == \"train\":\n","            data_train.append(row)\n","        else:\n","            data_test.append(row)\n","\n","    for rows_of_type in [data_train, data_test]:\n","        for row in rows_of_type:\n","            temp = []\n","            temp = np.array(temp)\n","            cou+=1\n","            print(f'Status {int(cou/length*100)}%', end='\\r')\n","            if row['type'] == \"train\":\n","                mfccs_feature = get_features(AUDIO_FILES_DIR + AUDIO_FILES[row['index']])\n","                for f in mfccs_feature:\n","                    x_train.append(f)\n","                    y_train.append(1 if row['dx'] == 'ProbableAD' else 0)\n","            else:\n","                f = get_features(AUDIO_FILES_DIR + AUDIO_FILES[row['index']])[0]\n","                x_test.append(f)\n","                y_test.append(1 if row['dx'] == 'ProbableAD' else 0)\n","    x_train = np.array(x_train)\n","    x_test = np.array(x_test)\n","    y_train = np.array(y_train)\n","    y_test = np.array(y_test)\n","    x_train = np.expand_dims(x_train, axis=3)\n","    x_test = np.expand_dims(x_test, axis=3)\n","    np.save('mfcc13.npy', {'x_train': x_train, 'x_test': x_test, 'y_train': y_train, 'y_test': y_test})\n","else:\n","    temp = np.load(LoadAddress, allow_pickle=True).item()\n","    x_train = np.array(temp['x_train'])\n","    x_test = np.array(temp['x_test'])\n","    y_train = np.array(temp['y_train'])\n","    y_test = np.array(temp['y_test'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x_train.shape, x_test.shape, y_train.shape, y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# create sequential model with 4 CNN layers then flatten then dense then output\n","from keras.layers import BatchNormalization, Dropout\n","from keras import regularizers\n","from sklearn.model_selection import KFold\n","import json\n","from gc import collect\n","\n","num_folds = 5\n","kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","# fig , ax = plt.subplots(5,2)\n","# fig.set_size_inches(20,30)\n","checkpointreach = False\n","for filter1 in [4,8,16,32]:\n","    for filter2 in [4,8,16,32]:\n","        for unit in [4,8,16,32]:\n","            for fac1 in [0.01,0.02,0.04]:\n","                for fac2 in [0.01, 0.02, 0.04]:\n","                    for fac3 in [0.01,0.02,0.04]:\n","                        acc_per_fold = []\n","                        loss_per_fold = []\n","                        fold_no = 1\n","                        history_fold = []\n","                        print(f'filter1: {filter1}, filter2: {filter2}, unit: {unit}, fac1: {fac1}, fac2: {fac2}, fac3: {fac3}')\n","                        if checkpointreach == False:\n","                            if filter1 == 32 and filter2 == 16 and unit == 16 and fac1 == 0.02 and fac2 == 0.02 and fac3 == 0.01:\n","                                checkpointreach = True\n","                                continue\n","                            else:\n","                                continue\n","                        for train, test in kfold.split(x_train, y_train):\n","                            keras.backend.clear_session()\n","                            collect()\n","                            model = keras.Sequential()\n","                            model.add(keras.layers.Conv2D(filter1, kernel_size=(3, 3), activation='relu', input_shape=(13, 2188, 1), kernel_regularizer=regularizers.l1(fac1)))\n","                            model.add(BatchNormalization())\n","                            model.add(keras.layers.MaxPooling2D((2, 2)))\n","                            model.add(keras.layers.Conv2D(filter2, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l1_l2(fac2)))\n","                            model.add(BatchNormalization())\n","                            model.add(keras.layers.MaxPooling2D((2, 2)))\n","                            model.add(keras.layers.Flatten())\n","                            model.add(Dropout(0.3))\n","                            model.add(keras.layers.Dense(unit, activation='relu', kernel_regularizer=regularizers.l2(fac3)))\n","                            model.add(keras.layers.Dense(1, activation='sigmoid'))\n","                            model.compile(optimizer='sgd',\n","                                          loss='binary_crossentropy',\n","                                          metrics=['accuracy'])\n","#                             print('------------------------------------------------------------------------')\n","#                             print(f'Training for fold {fold_no} ...')\n","                            rlrp = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n","                                                                    patience=3,\n","                                                                    verbose=0,\n","                                                                    factor=0.5,\n","                                                                    min_lr=0.00001)\n","                            earlystopping = keras.callbacks.EarlyStopping(monitor =\"val_accuracy\",\n","                                                      mode = 'auto', patience = 30,\n","                                                      restore_best_weights = True)\n","\n","                            history=model.fit(x_train[train], y_train[train], batch_size=64, epochs=100, validation_data=(x_train[test], y_train[test]), callbacks=[rlrp,earlystopping],verbose=0)\n","\n","                            # Generate generalization metrics\n","                            scores = model.evaluate(x_test,y_test, verbose=0)\n","                            print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n","                            acc_per_fold.append(scores[1] * 100)\n","                            loss_per_fold.append(scores[0])\n","\n","                            # Increase fold number\n","                            fold_no = fold_no + 1\n","                        temp = {}\n","                        temp['filter1'] = filter1\n","                        temp['filter2'] = filter2\n","                        temp['unit'] = unit\n","                        temp['fac1'] = fac1\n","                        temp['fac2'] = fac2\n","                        temp['fac3'] = fac3\n","                        temp['acc'] = acc_per_fold\n","                        temp['loss'] = loss_per_fold\n","#                         temp['history'] = history_fold\n","                        # append in the json\n","                        with open('result.json', 'a') as fp:\n","                            json.dump(temp, fp)\n","                            fp.write('\\n')\n","                        print('------------------------------------------------------------------------')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# with open('result.json', 'r') as fp:\n","#     ParamSet = fp.readlines()\n","# ParamSet = [json.loads(x) for x in ParamSet]\n","# ParamSet = sorted(ParamSet, key = lambda i: sum(i['acc'])/num_folds,reverse=True)\n","# print(ParamSet[0])\n","# print(ParamSet[1])\n","# print(ParamSet[2])\n","# print(ParamSet[3])\n","# print(ParamSet[4])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
